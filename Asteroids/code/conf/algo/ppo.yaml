_target_: algos.get_algo
# PPO Algorithm Configuration
name: "ppo"
policy: "MlpPolicy"
learning_rate: 0.0003
n_steps: 4096
batch_size: 256
n_epochs: 5
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
normalize_advantage: true
ent_coef: 0.15
vf_coef: 0.5
max_grad_norm: 1.0
verbose: 1